{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09be5c9",
   "metadata": {},
   "source": [
    "# 07_Decision_Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439cb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a1d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac6c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Parts of the Code are based on: https://medium.com/@cjakuc/building-a-decision-tree-classifier-c00a08815c3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01493c3",
   "metadata": {},
   "source": [
    "### Implement Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d12826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeManager:\n",
    "    \"\"\"\n",
    "    NodeManager class is used to build the decision tree by storing\n",
    "    the following parameters:\n",
    "    class_prediction: prediction label\n",
    "    feature_idx: idx of feature for optimal split\n",
    "    threshold: threshold for optimal split\n",
    "    left: node below threshold\n",
    "    right: node above threshold\n",
    "    leftbranch/rightbranch: indicate which branch node is from parent\n",
    "    \"\"\"\n",
    "    def __init__(self, class_prediction, depth=None):\n",
    "        self.class_prediction = class_prediction\n",
    "        # feature index will be used to identify optimal split column\n",
    "        self.feature_idx = 0\n",
    "        # threshold will be used to store optimal split threshold\n",
    "        self.threshold = 0\n",
    "        # below threshold\n",
    "        self.left = None\n",
    "        # above threshold\n",
    "        self.right = None\n",
    "        # left to parent\n",
    "        self.leftbranch = False\n",
    "        # right to parent\n",
    "        self.rightbranch = False\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "    Class to build a decision tree with maximum depth maximum_depth.\n",
    "    Can be used with datasets with a variable number of features.\n",
    "    \"\"\"\n",
    "    def __init__(self, maximum_depth=None):\n",
    "        self.maximum_depth = maximum_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the decision tree to a training set.\n",
    "        \"\"\"\n",
    "        # identify number of classes\n",
    "        self.n_classes = len(np.unique(y_train))\n",
    "        # build decision tree classifier with build_tree method\n",
    "        self.tree = self.build_tree(X_train, y_train)\n",
    "        #print('...decision tree fitted.')\n",
    "\n",
    "    def next_split(self, data, labels):\n",
    "        \"\"\"\n",
    "        Takes data and labels of a node as input and returns column\n",
    "        and threshold for optimal next split into child nodes with min\n",
    "        impurity. If data contains no samples or minimal\n",
    "        parent impurity was smaller than new minimal \n",
    "        impurity, it returns None,None.\n",
    "        \"\"\"\n",
    "        # Check if the subset contains at least one observation\n",
    "        n_data_points = labels.size\n",
    "        # If not, return None,None for col,threshold\n",
    "        if n_data_points <= 1:\n",
    "            return None, None\n",
    "        \n",
    "        # reshape labels\n",
    "        labels = labels.reshape(n_data_points,)\n",
    "        # count classes in parent node\n",
    "        count_in_parent = [np.count_nonzero(labels == c) for c in range(self.n_classes)]\n",
    "\n",
    "        # Get the minimum impurity of the parent node to compare with new min impurity \n",
    "        parent_impurity = 1.0 - sum((n / n_data_points) ** 2 for n in count_in_parent)\n",
    "        \n",
    "        # combine data and labels to facilitate sorting\n",
    "        dataset = np.column_stack((data,labels))\n",
    "        # Initialize empty G_list\n",
    "        G_list = []\n",
    "\n",
    "        # iteraete over columns (features)\n",
    "        for col in range(0, dataset.shape[1]-1):\n",
    "            # sort by respective column\n",
    "            dataset = dataset[dataset[:, col].argsort()]\n",
    "            \n",
    "            # empty list to store results for every column\n",
    "            G_col_list = []\n",
    "\n",
    "            # iterate over elements in col\n",
    "            for i in range(0,len(dataset)-1):\n",
    "                # compute threshold as mean of two elements\n",
    "                threshold = (dataset[i,col] + dataset[i+1,col])/2\n",
    "                # number of values equal above threshold\n",
    "                n1 = (dataset[:,col] >= threshold).sum()\n",
    "                # number of values below threshold\n",
    "                n2 = (dataset[:,col] < threshold).sum()\n",
    "                # total number of elements\n",
    "                n_all = n1+n2\n",
    "                # number of elements in node 1 which belong to class 0\n",
    "                l1_class0 = (dataset[dataset[:,col]>=threshold][:,-1] == 0).sum()\n",
    "                # number of elements in node 1 which belong to class 1\n",
    "                l1_class1 = (dataset[dataset[:,col]>=threshold][:,-1] == 1).sum()\n",
    "                # gini impurity of node 1\n",
    "                if n1 != 0:\n",
    "                    l1_G = 1 - (l1_class0/n1)**2 - (l1_class1/n1)**2\n",
    "                else: \n",
    "                    l1_G = 0\n",
    "                # number of elements in node 2 which belong to class 0\n",
    "                l2_class0 = (dataset[dataset[:,col]<threshold][:,-1] == 0).sum()\n",
    "                # number of elements in node 2 which belong to class 1\n",
    "                l2_class1 = (dataset[dataset[:,col]<threshold][:,-1] == 1).sum()\n",
    "                # gini impurity of node 2\n",
    "                if n2 != 0:\n",
    "                    l2_G = 1 - (l2_class0/n2)**2 - (l2_class1/n2)**2\n",
    "                else:\n",
    "                    l2_G = 0\n",
    "                # gini impurity of whole node (weightes impurities of node 1 and node 2)\n",
    "                G = n1/n_all*l1_G + n2/n_all*l2_G\n",
    "                # store gini impority and threshold\n",
    "                result = np.array([threshold, G])\n",
    "                G_col_list.append(result)\n",
    "\n",
    "            # identify and store smallest gini impurity\n",
    "            G_col_arr = np.array(G_col_list)\n",
    "            idx_smallest_G = np.array(G_col_list)[:,1].argmin()\n",
    "            G_list.append(G_col_arr[idx_smallest_G])\n",
    "\n",
    "        G_arr = np.array(G_list)\n",
    "        # The column with the smallest impurity\n",
    "        optimal_col = G_arr[:,-1].argmin()\n",
    "        # min gini impurity\n",
    "        min_impurity = G_arr[optimal_col, -1]\n",
    "        # The respective threshold of the column with the smallest impurity\n",
    "        optimal_threshold = G_arr[optimal_col][0]\n",
    "        \n",
    "        # check if min_impurity is larger than parent impurity (no improvement):\n",
    "        # If this is the case, return None, None for col and threshold\n",
    "        if min_impurity >= parent_impurity:\n",
    "            return None,None\n",
    "\n",
    "        # If impurity improved, return the optimal column and the optimal threshold\n",
    "        return optimal_col, optimal_threshold\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Build the decision tree until the maximum depth is reached.\n",
    "        \"\"\"\n",
    "\n",
    "        # count the occurance of each class\n",
    "        class_occurrence = [np.count_nonzero(y == i) for i in range(self.n_classes)]\n",
    "        # class prediction is the class with the largest occurence\n",
    "        class_prediction = np.argmax(class_occurrence)\n",
    "        # Instantiate an empty Node using the NodeManager class\n",
    "        node = NodeManager(class_prediction=class_prediction,depth=depth)\n",
    "        # Create a variable in the node class for the number of samples\n",
    "        node.samples = y.size\n",
    "        # As long as max depth is not reached...\n",
    "        if depth < self.maximum_depth:\n",
    "            # apply next_split method to get col and threshold of optimal split\n",
    "            # Returns None of Leaf is reached (branch is finished)\n",
    "            col, threshold = self.next_split(X, y)\n",
    "            # If leaf is not reached...\n",
    "            if col and threshold:\n",
    "                # split the data and labels into right and left using col and threshold\n",
    "                # left index for data points below threshold\n",
    "                left_idx = X[:, col] < threshold\n",
    "                # right index for datapoints eqal or above threshold\n",
    "                right_idx = X[:, col] >= threshold\n",
    "                # dataset of left node\n",
    "                X_left = X[left_idx]\n",
    "                y_left = y[left_idx]\n",
    "                # dataset of right node\n",
    "                X_right = X[right_idx]\n",
    "                y_right = y[right_idx]\n",
    "                # Store parameters to Node manager\n",
    "                node.feature_idx = col\n",
    "                node.threshold = threshold\n",
    "                # Apply build_tree function inside build_tree to build the next level of nodes with left node\n",
    "                # Increase depth counter by 1\n",
    "                node.left = self.build_tree(X_left, y_left, depth+1)\n",
    "                # store info that node was left side of parent node in node manager\n",
    "                node.left.leftbranch = True\n",
    "                # Apply build_tree function inside build_tree to build the next level of nodes with right node\n",
    "                node.right = self.build_tree(X_right, y_right, depth+1)\n",
    "                # store info that node was right side of parent node in node manager\n",
    "                node.right.rightbranch = True\n",
    "                \n",
    "        return node\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Takes X_test as input and predicts labels\n",
    "        using the built decision tree. \n",
    "        Uses the stored information about split col,\n",
    "        split threshold, left or right, leftbranch or \n",
    "        right branch from NodeManager.\n",
    "        \"\"\"\n",
    "        # assign root node\n",
    "        node = self.tree\n",
    "        # empty prediction list\n",
    "        y_preds = []\n",
    "        # Iterate over data points in X_test\n",
    "        for data_point in X_test:\n",
    "            # Reasign root node\n",
    "            node = self.tree\n",
    "            # Go through the decision nodes of the tree and use optimal\n",
    "            # split columns and optimal thresholds to predict\n",
    "            # classification of data point.\n",
    "            while node.left:\n",
    "                # Make Predictions with left node\n",
    "                if data_point[node.feature_idx] < node.threshold:\n",
    "                    node = node.left\n",
    "                # Make Predictions with right node\n",
    "                else:\n",
    "                    node = node.right\n",
    "            # append prediction to prediction list\n",
    "            y_preds.append(node.class_prediction)\n",
    "            \n",
    "        # return predictions as numpy array\n",
    "        return np.array(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccbf01",
   "metadata": {},
   "source": [
    "### Test Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29dcea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, shuffle=True, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Split data into training and testing set.\n",
    "    \"\"\"\n",
    "    n_train = int(X.shape[0]*(1-test_size))\n",
    "    indices = np.arange(len(X))\n",
    "    if shuffle: \n",
    "        np.random.shuffle(indices)\n",
    "    train = indices[:n_train]\n",
    "    test = indices[n_train:]\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49516fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "# train test split (30% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X=X, y=y, shuffle=True, test_size=0.3)\n",
    "\n",
    "# For binary classification: merge Iris virginica and Iris setosa into one class.\n",
    "y_train = np.where(y_train==2, 0, y_train)\n",
    "y_test = np.where(y_test==2, 0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40488bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showcase\n",
    "decision_tree = DecisionTree(maximum_depth=10)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "print('Predictions:')\n",
    "decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a264ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_pred, y_test):\n",
    "    \"\"\"\n",
    "    Takes y_test and y_pred as input and\n",
    "    returns accuracy.\n",
    "    \"\"\"\n",
    "    n_accurate = (y_pred == y_test).sum()\n",
    "    n_total = len(y_test)\n",
    "    accuracy = n_accurate / n_total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "302899c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report Accuracy for five runs:\n",
    "def run_decision_tree(n_iterations=5):\n",
    "    \n",
    "    for i in range(0,n_iterations):\n",
    "        # instantiate decision tree with DecisionTree class\n",
    "        decision_tree = DecisionTree(maximum_depth=10)\n",
    "        # generate random subset idx\n",
    "        subset_idx = np.random.randint(low=0, high=len(X), size=75)\n",
    "        # select data with subset_idx\n",
    "        X_sub = X[subset_idx]\n",
    "        y_sub = y[subset_idx]\n",
    "        # train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X=X_sub, y=y_sub, shuffle=True, test_size=0.3)\n",
    "        # fit model\n",
    "        decision_tree.fit(X_train, y_train)\n",
    "        # predict y_hat\n",
    "        y_pred = decision_tree.predict(X_test)\n",
    "        # compute accuracy\n",
    "        acc = get_accuracy(y_pred, y_test)\n",
    "        print('Accuracy Score run {}: {}'.format(i+1,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "040e96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score run 1: 0.782608695652174\n",
      "Accuracy Score run 2: 0.6956521739130435\n",
      "Accuracy Score run 3: 0.6956521739130435\n",
      "Accuracy Score run 4: 0.6956521739130435\n",
      "Accuracy Score run 5: 0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "run_decision_tree(n_iterations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
